{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E0Rv4c-hU4bA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "idPJk2J7VB0p",
    "outputId": "cb7548c3-5554-4d95-891d-4d1a6f381e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-28 14:07:04--  https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1939 (1.9K) [text/plain]\n",
      "Saving to: ‘setup_google_colab.py’\n",
      "\n",
      "\r",
      "setup_google_colab.   0%[                    ]       0  --.-KB/s               \r",
      "setup_google_colab. 100%[===================>]   1.89K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-10-28 14:07:05 (21.8 MB/s) - ‘setup_google_colab.py’ saved [1939/1939]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    ! wget https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py -O setup_google_colab.py\n",
    "    import setup_google_colab\n",
    "    setup_google_colab.setup_week4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZs7pczQVJ38"
   },
   "source": [
    "**Data**\n",
    "\n",
    "to be generated randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W3obEv34VB5f"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HwrgHvNNVB-s"
   },
   "outputs": [],
   "source": [
    "def generate_equations(allowed_operators, dataset_size, min_value, max_value):\n",
    "    \"\"\"Generates pairs of equations and solutions to them.\n",
    "    \n",
    "       Each equation has a form of two integers with an operator in between.\n",
    "       Each solution is an integer with the result of the operaion.\n",
    "    \n",
    "        allowed_operators: list of strings, allowed operators.\n",
    "        dataset_size: an integer, number of equations to be generated.\n",
    "        min_value: an integer, min value of each operand.\n",
    "        max_value: an integer, max value of each operand.\n",
    "\n",
    "        result: a list of tuples of strings (equation, solution).\n",
    "    \"\"\"\n",
    "    sample = []\n",
    "    for _ in range(dataset_size):\n",
    "        ######################################\n",
    "        ######### YOUR CODE HERE #############\n",
    "        ######################################\n",
    "        a = random.randint(min_value, max_value)\n",
    "        b = random.randint(min_value, max_value)\n",
    "        op = random.choice(allowed_operators)\n",
    "        equation = str(a) + op + str(b)\n",
    "        solution = str(eval(equation))\n",
    "        sample.append((equation, solution))\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bbGJQdoOVCBt"
   },
   "outputs": [],
   "source": [
    "def test_generate_equations():\n",
    "    allowed_operators = ['+', '-']\n",
    "    dataset_size = 10\n",
    "    for (input_, output_) in generate_equations(allowed_operators, dataset_size, 0, 100):\n",
    "        if not (type(input_) is str and type(output_) is str):\n",
    "            return \"Both parts should be strings.\"\n",
    "        if eval(input_) != int(output_):\n",
    "            return \"The (equation: {!r}, solution: {!r}) pair is incorrect.\".format(input_, output_)\n",
    "    return \"Tests passed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "EEfGoIYeVCGw",
    "outputId": "cea5c22a-0937-4c83-adde-06e55137d7b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed.\n"
     ]
    }
   ],
   "source": [
    "print(test_generate_equations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jhogjc11VCOD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9foFYoBVVCTB"
   },
   "outputs": [],
   "source": [
    "allowed_operators = ['+', '-']\n",
    "dataset_size = 100000\n",
    "data = generate_equations(allowed_operators, dataset_size, min_value=0, max_value=9999)\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCfjHRpdVket"
   },
   "source": [
    "**prepare data for neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QRXj8tDSVCVt"
   },
   "outputs": [],
   "source": [
    "word2id = {symbol:i for i, symbol in enumerate('#^$+-1234567890')}\n",
    "id2word = {i:symbol for symbol, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSMQf1_nVqdf"
   },
   "source": [
    "special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TrYxWAzjVCYr"
   },
   "outputs": [],
   "source": [
    "start_symbol = '^'\n",
    "end_symbol = '$'\n",
    "padding_symbol = '#'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joKv1hBwVvle"
   },
   "source": [
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1Fay0l5mVCdk"
   },
   "outputs": [],
   "source": [
    "def sentence_to_ids(sentence, word2id, padded_len):\n",
    "    \"\"\" Converts a sequence of symbols to a padded sequence of their ids.\n",
    "    \n",
    "      sentence: a string, input/output sequence of symbols.\n",
    "      word2id: a dict, a mapping from original symbols to ids.\n",
    "      padded_len: an integer, a desirable length of the sequence.\n",
    "\n",
    "      result: a tuple of (a list of ids, an actual length of sentence).\n",
    "    \"\"\"\n",
    "    sent_len = min(len(sentence) + 1, padded_len)\n",
    "    plen = max(0, padded_len - sent_len)\n",
    "    sent_ids = [word2id[word] for word in sentence[:sent_len - 1]] + [word2id[end_symbol]] + [word2id[padding_symbol]]*plen  \n",
    "    #sent_ids = ######### YOUR CODE HERE #############\n",
    "    #sent_len = ######### YOUR CODE HERE #############\n",
    "    \n",
    "    return sent_ids, sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cCyaA3XQVCgO"
   },
   "outputs": [],
   "source": [
    "def test_sentence_to_ids():\n",
    "    sentences = [(\"123+123\", 7), (\"123+123\", 8), (\"123+123\", 10)]\n",
    "    expected_output = [([5, 6, 7, 3, 5, 6, 2], 7), \n",
    "                       ([5, 6, 7, 3, 5, 6, 7, 2], 8), \n",
    "                       ([5, 6, 7, 3, 5, 6, 7, 2, 0, 0], 8)] \n",
    "    for (sentence, padded_len), (sentence_ids, expected_length) in zip(sentences, expected_output):\n",
    "        output, length = sentence_to_ids(sentence, word2id, padded_len)\n",
    "        if output != sentence_ids:\n",
    "            return(\"Convertion of '{}' for padded_len={} to {} is incorrect.\".format(\n",
    "                sentence, padded_len, output))\n",
    "        if length != expected_length:\n",
    "            return(\"Convertion of '{}' for padded_len={} has incorrect actual length {}.\".format(\n",
    "                sentence, padded_len, length))\n",
    "    return(\"Tests passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "N9SnzFCJVCn9",
    "outputId": "0b9b2656-bbe0-4b95-bf43-48651931f893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed.\n"
     ]
    }
   ],
   "source": [
    "print(test_sentence_to_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LdOexoeZVCq1"
   },
   "outputs": [],
   "source": [
    "def ids_to_sentence(ids, id2word):\n",
    "    \"\"\" Converts a sequence of ids to a sequence of symbols.\n",
    "    \n",
    "          ids: a list, indices for the padded sequence.\n",
    "          id2word:  a dict, a mapping from ids to original symbols.\n",
    "\n",
    "          result: a list of symbols.\n",
    "    \"\"\"\n",
    " \n",
    "    return [id2word[i] for i in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q_6PRvYWDA3"
   },
   "source": [
    "generating batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IQLqkpv1VCuG"
   },
   "outputs": [],
   "source": [
    "def batch_to_ids(sentences, word2id, max_len):\n",
    "    \"\"\"Prepares batches of indices. \n",
    "    \n",
    "       Sequences are padded to match the longest sequence in the batch,\n",
    "       if it's longer than max_len, then max_len is used instead.\n",
    "\n",
    "        sentences: a list of strings, original sequences.\n",
    "        word2id: a dict, a mapping from original symbols to ids.\n",
    "        max_len: an integer, max len of sequences allowed.\n",
    "\n",
    "        result: a list of lists of ids, a list of actual lengths.\n",
    "    \"\"\"\n",
    "    \n",
    "    max_len_in_batch = min(max(len(s) for s in sentences) + 1, max_len)\n",
    "    batch_ids, batch_ids_len = [], []\n",
    "    for sentence in sentences:\n",
    "        ids, ids_len = sentence_to_ids(sentence, word2id, max_len_in_batch)\n",
    "        batch_ids.append(ids)\n",
    "        batch_ids_len.append(ids_len)\n",
    "    return batch_ids, batch_ids_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vykySDFUVC0u"
   },
   "outputs": [],
   "source": [
    "def generate_batches(samples, batch_size=64):\n",
    "    X, Y = [], []\n",
    "    for i, (x, y) in enumerate(samples, 1):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        if i % batch_size == 0:\n",
    "            yield X, Y\n",
    "            X, Y = [], []\n",
    "    if X and Y:\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "_LrH4bmQVC4y",
    "outputId": "cfae1d3a-c4b6-4841-dc94-b89b175268fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ('2572+7587', '10159')\n",
      "Ids: [[6, 9, 11, 6, 3, 11, 9, 12, 11, 2], [5, 14, 5, 9, 13, 2, 0, 0, 0, 0]]\n",
      "Sentences lengths: [10, 6]\n"
     ]
    }
   ],
   "source": [
    "sentences = train_set[0]\n",
    "ids, sent_lens = batch_to_ids(sentences, word2id, max_len=10)\n",
    "print('Input:', sentences)\n",
    "print('Ids: {}\\nSentences lengths: {}'.format(ids, sent_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxNTbP70WMX_"
   },
   "source": [
    "**Encoder Decoder architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "VkQ4EqWMhEi4",
    "outputId": "14954de2-761d-4a91-bfc2-cc2b8efa70a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.19.2)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.35.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.33.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (50.3.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.1)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "YRjY5ayyVCy8",
    "outputId": "b374d59c-84b5-48b8-c5b8-049320d73edc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf <-- it throws error regarding placeholders\n",
    "#import tensorflow as tf2\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "mRHnHfgtVClI"
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FI5NVUniVCjP"
   },
   "outputs": [],
   "source": [
    "def declare_placeholders(self):\n",
    "    \"\"\"Specifies placeholders for the model.\"\"\"\n",
    "    \n",
    "    # Placeholders for input and its actual lengths.\n",
    "    self.input_batch = tf.placeholder(shape=(None, None), dtype=tf.int32, name='input_batch')\n",
    "    self.input_batch_lengths = tf.placeholder(shape=(None, ), dtype=tf.int32, name='input_batch_lengths')\n",
    "    \n",
    "    # Placeholders for groundtruth and its actual lengths.\n",
    "    self.ground_truth = tf.placeholder(shape=(None, None), dtype=tf.int32, name='ground_truth')\n",
    "    self.ground_truth_lengths = tf.placeholder(shape=(None, ), dtype=tf.int32, name='ground_truth_lengths')\n",
    "    #self.ground_truth = ######### YOUR CODE HERE #############\n",
    "    #self.ground_truth_lengths = ######### YOUR CODE HERE #############\n",
    "        \n",
    "    self.dropout_ph = tf.placeholder_with_default(tf.cast(1.0, tf.float32), shape=[])\n",
    "    self.learning_rate_ph = tf.placeholder(dtype=tf.float32, shape=[])\n",
    "    #self.learning_rate_ph = ######### YOUR CODE HERE #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "VyJkcpl2VCb2"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__declare_placeholders = classmethod(declare_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PvFRTHSzVCQY"
   },
   "outputs": [],
   "source": [
    "def create_embeddings(self, vocab_size, embeddings_size):\n",
    "    \"\"\"Specifies embeddings layer and embeds an input batch.\"\"\"\n",
    "     \n",
    "    random_initializer = tf.random_uniform((vocab_size, embeddings_size), -1.0, 1.0)\n",
    "    #self.embeddings = ######### YOUR CODE HERE ############# \n",
    "    self.embeddings = tf.Variable(random_initializer, dtype=tf.float32)\n",
    "    \n",
    "    # Perform embeddings lookup for self.input_batch. \n",
    "    #self.input_batch_embedded = ######### YOUR CODE HERE #############\n",
    "    self.input_batch_embedded = tf.nn.embedding_lookup(self.embeddings, self.input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "DFtfonP1VCLe"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__create_embeddings = classmethod(create_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKcQ63AIW3AE"
   },
   "source": [
    "**Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "waUu8OwOVCJ9"
   },
   "outputs": [],
   "source": [
    "def build_encoder(self, hidden_size):\n",
    "    \"\"\"Specifies encoder architecture and computes its output.\"\"\"\n",
    "    \n",
    "    # Create GRUCell with dropout.\n",
    "    encoder_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.GRUCell(hidden_size), input_keep_prob=self.dropout_ph)\n",
    "    \n",
    "    # Create RNN with the predefined cell.\n",
    "    _, self.final_encoder_state = tf.nn.dynamic_rnn(encoder_cell,\n",
    "                                                    self.input_batch_embedded,\n",
    "                                                    sequence_length=self.input_batch_lengths,\n",
    "                                                    dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "JyCD24nGVCEj"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__build_encoder = classmethod(build_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riN4ghIsXBpb"
   },
   "source": [
    "**Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tYyZc1QGVB8d"
   },
   "outputs": [],
   "source": [
    "def build_decoder(self, hidden_size, vocab_size, max_iter, start_symbol_id, end_symbol_id):\n",
    "    \"\"\"Specifies decoder architecture and computes the output.\n",
    "    \n",
    "        Uses different helpers:\n",
    "          - for train: feeding ground truth\n",
    "          - for inference: feeding generated output\n",
    "\n",
    "        As a result, self.train_outputs and self.infer_outputs are created. \n",
    "        Each of them contains two fields:\n",
    "          rnn_output (predicted logits)\n",
    "          sample_id (predictions).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use start symbols as the decoder inputs at the first time step.\n",
    "    batch_size = tf.shape(self.input_batch)[0]\n",
    "    start_tokens = tf.fill([batch_size], start_symbol_id)\n",
    "    ground_truth_as_input = tf.concat([tf.expand_dims(start_tokens, 1), self.ground_truth], 1)\n",
    "    \n",
    "    # Use the embedding layer defined before to lookup embedings for ground_truth_as_input. \n",
    "    self.ground_truth_embedded = tf.nn.embedding_lookup(self.embeddings, ground_truth_as_input)\n",
    "     \n",
    "    # Create TrainingHelper for the train stage.\n",
    "    #train_helper = tfa.seq2seq.TrainingSampler(self.ground_truth_embedded, self.ground_truth_lengths)\n",
    "    train_helper = tf.contrib.seq2seq.TrainingHelper(self.ground_truth_embedded, self.ground_truth_lengths)\n",
    "    #train_helper = tf2.contrib.seq2seq.TrainingHelper(self.ground_truth_embedded, self.ground_truth_lengths)\n",
    "    \n",
    "    # Create GreedyEmbeddingHelper for the inference stage.\n",
    "    # You should provide the embedding layer, start_tokens and index of the end symbol.\n",
    "    #infer_helper = tf2.contrib.seq2seq.GreedyEmbeddingHelper(self.embeddings, start_tokens, end_symbol_id)\n",
    "    infer_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(self.embeddings, start_tokens, end_symbol_id)\n",
    "    \n",
    "  \n",
    "    def decode(helper, scope, reuse=None):\n",
    "        \"\"\"Creates decoder and return the results of the decoding with a given helper.\"\"\"\n",
    "        \n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            # Create GRUCell with dropout. Do not forget to set the reuse flag properly.\n",
    "            decoder_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.GRUCell(hidden_size, reuse=reuse),\n",
    "                                                         input_keep_prob=self.dropout_ph)\n",
    "            \n",
    "            # Create a projection wrapper.\n",
    "            #decoder_cell = tf2.contrib.rnn.OutputProjectionWrapper(decoder_cell, vocab_size, reuse=reuse)\n",
    "            decoder_cell = tf.contrib.rnn.OutputProjectionWrapper(decoder_cell, vocab_size, reuse=reuse)\n",
    "            \n",
    "            # Create BasicDecoder, pass the defined cell, a helper, and initial state.\n",
    "            # The initial state should be equal to the final state of the encoder!\n",
    "            #decoder = tf2.contrib.seq2seq.BasicDecoder(decoder_cell, helper, self.final_encoder_state)\n",
    "            decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper, self.final_encoder_state)\n",
    "            \n",
    "            # The first returning argument of dynamic_decode contains two fields:\n",
    "            #   rnn_output (predicted logits)\n",
    "            #   sample_id (predictions)\n",
    "            #outputs, _, _ = tf2.contrib.seq2seq.dynamic_decode(decoder=decoder, maximum_iterations=max_iter, \n",
    "            #                                                  output_time_major=False, impute_finished=True)\n",
    "            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder=decoder, maximum_iterations=max_iter, \n",
    "                                                              output_time_major=False, impute_finished=True)\n",
    "\n",
    "            return outputs\n",
    "        \n",
    "    self.train_outputs = decode(train_helper, 'decode')\n",
    "    self.infer_outputs = decode(infer_helper, 'decode', reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LZx36gD7VB3h"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__build_decoder = classmethod(build_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8kytevFKXVOy"
   },
   "outputs": [],
   "source": [
    "def compute_loss(self):\n",
    "    \"\"\"Computes sequence loss (masked cross-entopy loss with logits).\"\"\"\n",
    "    \n",
    "    weights = tf.cast(tf.sequence_mask(self.ground_truth_lengths), dtype=tf.float32)\n",
    "    \n",
    "    self.loss = tf.contrib.seq2seq.sequence_loss(self.train_outputs.rnn_output, self.ground_truth, weights)\n",
    "    #self.loss = tf2.contrib.seq2seq.sequence_loss(self.train_outputs.rnn_output, self.ground_truth, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Le27GcshXVWZ"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__compute_loss = classmethod(compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ylCLRyGfXVbu"
   },
   "outputs": [],
   "source": [
    "def perform_optimization(self):\n",
    "    \"\"\"Specifies train_op that optimizes self.loss.\"\"\"\n",
    "    \n",
    "    #self.train_op = tf2.contrib.layers.optimize_loss(loss=self.loss,\n",
    "    self.train_op = tf.contrib.layers.optimize_loss(loss=self.loss,\n",
    "                                                    global_step=tf.train.get_global_step(),\n",
    "                                                    learning_rate=self.learning_rate_ph,\n",
    "                                                    optimizer='Adam',\n",
    "                                                    clip_gradients=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wdasHAzGXVg3"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__perform_optimization = classmethod(perform_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "LAGSYylWXVoT"
   },
   "outputs": [],
   "source": [
    "def init_model(self, vocab_size, embeddings_size, hidden_size, \n",
    "               max_iter, start_symbol_id, end_symbol_id, padding_symbol_id):\n",
    "    \n",
    "    self.__declare_placeholders()\n",
    "    self.__create_embeddings(vocab_size, embeddings_size)\n",
    "    self.__build_encoder(hidden_size)\n",
    "    self.__build_decoder(hidden_size, vocab_size, max_iter, start_symbol_id, end_symbol_id)\n",
    "    \n",
    "    # Compute loss and back-propagate.\n",
    "    self.__compute_loss()\n",
    "    self.__perform_optimization()\n",
    "    \n",
    "    # Get predictions for evaluation.\n",
    "    self.train_predictions = self.train_outputs.sample_id\n",
    "    self.infer_predictions = self.infer_outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "AGI3VRj6XVv5"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.__init__ = classmethod(init_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OviIy1gEXrka"
   },
   "source": [
    "**Train the NW and predict the output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "FklBYGyBXV3l"
   },
   "outputs": [],
   "source": [
    "def train_on_batch(self, session, X, X_seq_len, Y, Y_seq_len, learning_rate, dropout_keep_probability):\n",
    "    feed_dict = {\n",
    "            self.input_batch: X,\n",
    "            self.input_batch_lengths: X_seq_len,\n",
    "            self.ground_truth: Y,\n",
    "            self.ground_truth_lengths: Y_seq_len,\n",
    "            self.learning_rate_ph: learning_rate,\n",
    "            self.dropout_ph: dropout_keep_probability\n",
    "        }\n",
    "    pred, loss, _ = session.run([\n",
    "            self.train_predictions,\n",
    "            self.loss,\n",
    "            self.train_op], feed_dict=feed_dict)\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Tgr7cnGkXV8a"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.train_on_batch = classmethod(train_on_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Yl8Ai7lCXWD4"
   },
   "outputs": [],
   "source": [
    "def predict_for_batch(self, session, X, X_seq_len):\n",
    "    feed_dict = {\n",
    "            self.input_batch: X,\n",
    "            self.input_batch_lengths: X_seq_len\n",
    "        }\n",
    "    pred = session.run([\n",
    "            self.infer_predictions\n",
    "        ], feed_dict=feed_dict)[0]\n",
    "    return pred\n",
    "\n",
    "def predict_for_batch_with_loss(self, session, X, X_seq_len, Y, Y_seq_len):\n",
    "    feed_dict = {\n",
    "            self.input_batch: X,\n",
    "            self.input_batch_lengths: X_seq_len,\n",
    "            self.ground_truth: Y,\n",
    "            self.ground_truth_lengths: Y_seq_len\n",
    "        }\n",
    "    pred, loss = session.run([\n",
    "            self.infer_predictions,\n",
    "            self.loss,\n",
    "        ], feed_dict=feed_dict)\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "yCHjhc0rXWG7"
   },
   "outputs": [],
   "source": [
    "Seq2SeqModel.predict_for_batch = classmethod(predict_for_batch)\n",
    "Seq2SeqModel.predict_for_batch_with_loss = classmethod(predict_for_batch_with_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lrbfNCWX8rH"
   },
   "source": [
    "**Running the experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "N4rPU8HZXWLj",
    "outputId": "6395fcfb-b678-4013-e092-f4087ddace9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-d1ab5c025a0b>:5: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-25-d1ab5c025a0b>:11: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Seq2SeqModel(vocab_size=len(word2id),\n",
    "                     embeddings_size=20,\n",
    "                     hidden_size=512, \n",
    "                     max_iter=7,\n",
    "                     start_symbol_id=word2id['^'],\n",
    "                     end_symbol_id=word2id['$'],\n",
    "                     padding_symbol_id=word2id['#'])\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 10\n",
    "learning_rate = 0.001\n",
    "dropout_keep_probability = 0.5\n",
    "max_len = 20\n",
    "\n",
    "n_step = int(len(train_set) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hOKUgAa9XWBr",
    "outputId": "7a4913bb-b363-4d5e-fcb1-dee06ac0b692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training... \n",
      "\n",
      "Train: epoch 1\n",
      "Epoch: [1/10], step: [1/625], loss: 2.694906\n",
      "Epoch: [1/10], step: [201/625], loss: 1.823685\n",
      "Epoch: [1/10], step: [401/625], loss: 1.741223\n",
      "Epoch: [1/10], step: [601/625], loss: 1.671240\n",
      "Test: epoch 1 loss: 1.614871\n",
      "X: 6662-3002$\n",
      "Y: 3660$#\n",
      "O: 3777$#\n",
      "\n",
      "X: 4398+3580$\n",
      "Y: 7978$#\n",
      "O: 8737$#\n",
      "\n",
      "X: 1499+754$#\n",
      "Y: 2253$#\n",
      "O: 5737$#\n",
      "\n",
      "Train: epoch 2\n",
      "Epoch: [2/10], step: [1/625], loss: 1.630475\n",
      "Epoch: [2/10], step: [201/625], loss: 1.554505\n",
      "Epoch: [2/10], step: [401/625], loss: 1.527237\n",
      "Epoch: [2/10], step: [601/625], loss: 1.486991\n",
      "Test: epoch 2 loss: 1.4154902\n",
      "X: 862+2218$#\n",
      "Y: 3080$#\n",
      "O: 3122$#\n",
      "\n",
      "X: 3646-7781$\n",
      "Y: -4135$\n",
      "O: -4942$\n",
      "\n",
      "X: 5988-5801$\n",
      "Y: 187$##\n",
      "O: 133$##\n",
      "\n",
      "Train: epoch 3\n",
      "Epoch: [3/10], step: [1/625], loss: 1.481238\n",
      "Epoch: [3/10], step: [201/625], loss: 1.456859\n",
      "Epoch: [3/10], step: [401/625], loss: 1.402766\n",
      "Epoch: [3/10], step: [601/625], loss: 1.388545\n",
      "Test: epoch 3 loss: 1.3493475\n",
      "X: 8257+7930$\n",
      "Y: 16187$\n",
      "O: 16111$\n",
      "\n",
      "X: 2001+9252$\n",
      "Y: 11253$\n",
      "O: 11111$\n",
      "\n",
      "X: 7352-8916$\n",
      "Y: -1564$\n",
      "O: -1111$\n",
      "\n",
      "Train: epoch 4\n",
      "Epoch: [4/10], step: [1/625], loss: 1.403734\n",
      "Epoch: [4/10], step: [201/625], loss: 1.385453\n",
      "Epoch: [4/10], step: [401/625], loss: 1.336478\n",
      "Epoch: [4/10], step: [601/625], loss: 1.376843\n",
      "Test: epoch 4 loss: 1.3147979\n",
      "X: 4102+962$#\n",
      "Y: 5064$#\n",
      "O: 5442$#\n",
      "\n",
      "X: 2665-8331$\n",
      "Y: -5666$\n",
      "O: -5442$\n",
      "\n",
      "X: 579-1483$#\n",
      "Y: -904$#\n",
      "O: -844$#\n",
      "\n",
      "Train: epoch 5\n",
      "Epoch: [5/10], step: [1/625], loss: 1.351145\n",
      "Epoch: [5/10], step: [201/625], loss: 1.343761\n",
      "Epoch: [5/10], step: [401/625], loss: 1.362225\n",
      "Epoch: [5/10], step: [601/625], loss: 1.334493\n",
      "Test: epoch 5 loss: 1.2806861\n",
      "X: 6965+9992$\n",
      "Y: 16957$\n",
      "O: 17285$\n",
      "\n",
      "X: 75-2932$##\n",
      "Y: -2857$\n",
      "O: -2616$\n",
      "\n",
      "X: 3908+7107$\n",
      "Y: 11015$\n",
      "O: 11108$\n",
      "\n",
      "Train: epoch 6\n",
      "Epoch: [6/10], step: [1/625], loss: 1.339833\n",
      "Epoch: [6/10], step: [201/625], loss: 1.290877\n",
      "Epoch: [6/10], step: [401/625], loss: 1.314526\n",
      "Epoch: [6/10], step: [601/625], loss: 1.287459\n",
      "Test: epoch 6 loss: 1.2403388\n",
      "X: 9895+2304$\n",
      "Y: 12199$\n",
      "O: 12121$\n",
      "\n",
      "X: 1251+4107$\n",
      "Y: 5358$#\n",
      "O: 5327$#\n",
      "\n",
      "X: 2587-2099$\n",
      "Y: 488$##\n",
      "O: 740$##\n",
      "\n",
      "Train: epoch 7\n",
      "Epoch: [7/10], step: [1/625], loss: 1.270930\n",
      "Epoch: [7/10], step: [201/625], loss: 1.229542\n",
      "Epoch: [7/10], step: [401/625], loss: 1.187450\n",
      "Epoch: [7/10], step: [601/625], loss: 1.168045\n",
      "Test: epoch 7 loss: 1.0671917\n",
      "X: 7060-1902$\n",
      "Y: 5158$#\n",
      "O: 5184$#\n",
      "\n",
      "X: 8195-8875$\n",
      "Y: -680$#\n",
      "O: -1151$\n",
      "\n",
      "X: 4395+4999$\n",
      "Y: 9394$#\n",
      "O: 9368$#\n",
      "\n",
      "Train: epoch 8\n",
      "Epoch: [8/10], step: [1/625], loss: 1.116993\n",
      "Epoch: [8/10], step: [201/625], loss: 1.089808\n",
      "Epoch: [8/10], step: [401/625], loss: 1.070217\n",
      "Epoch: [8/10], step: [601/625], loss: 1.006686\n",
      "Test: epoch 8 loss: 0.9871108\n",
      "X: 2004-7992$\n",
      "Y: -5988$\n",
      "O: -5866$\n",
      "\n",
      "X: 2398+6259$\n",
      "Y: 8657$#\n",
      "O: 8693$#\n",
      "\n",
      "X: 7982+2039$\n",
      "Y: 10021$\n",
      "O: 10008$\n",
      "\n",
      "Train: epoch 9\n",
      "Epoch: [9/10], step: [1/625], loss: 1.032814\n",
      "Epoch: [9/10], step: [201/625], loss: 1.013550\n",
      "Epoch: [9/10], step: [401/625], loss: 1.015740\n",
      "Epoch: [9/10], step: [601/625], loss: 1.041467\n",
      "Test: epoch 9 loss: 0.95919216\n",
      "X: 1596-2405$\n",
      "Y: -809$#\n",
      "O: -846$#\n",
      "\n",
      "X: 1352+7956$\n",
      "Y: 9308$#\n",
      "O: 9306$#\n",
      "\n",
      "X: 789+8280$#\n",
      "Y: 9069$#\n",
      "O: 9086$#\n",
      "\n",
      "Train: epoch 10\n",
      "Epoch: [10/10], step: [1/625], loss: 1.012231\n",
      "Epoch: [10/10], step: [201/625], loss: 1.042065\n",
      "Epoch: [10/10], step: [401/625], loss: 0.984445\n",
      "Epoch: [10/10], step: [601/625], loss: 0.961371\n",
      "Test: epoch 10 loss: 0.89818335\n",
      "X: 5012-719$#\n",
      "Y: 4293$#\n",
      "O: 4319$#\n",
      "\n",
      "X: 2315-8492$\n",
      "Y: -6177$\n",
      "O: -6188$\n",
      "\n",
      "X: 4412-4734$\n",
      "Y: -322$#\n",
      "O: -330$#\n",
      "\n",
      "\n",
      "...training finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "            \n",
    "invalid_number_prediction_counts = []\n",
    "all_model_predictions = []\n",
    "all_ground_truth = []\n",
    "\n",
    "print('Start training... \\n')\n",
    "for epoch in range(n_epochs):  \n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "    \n",
    "    print('Train: epoch', epoch + 1)\n",
    "    for n_iter, (X_batch, Y_batch) in enumerate(generate_batches(train_set, batch_size=batch_size)):\n",
    "        ######################################\n",
    "        ######### YOUR CODE HERE #############\n",
    "        ######################################\n",
    "        # prepare the data (X_batch and Y_batch) for training\n",
    "        # using function batch_to_ids\n",
    "        X, X_seq_len = batch_to_ids(X_batch, word2id, max_len)\n",
    "        Y, Y_seq_len = batch_to_ids(Y_batch, word2id, max_len)\n",
    "        predictions, loss = model.train_on_batch(session, X, X_seq_len, Y, Y_seq_len, learning_rate, dropout_keep_probability)\n",
    "        \n",
    "        if n_iter % 200 == 0:\n",
    "            print(\"Epoch: [%d/%d], step: [%d/%d], loss: %f\" % (epoch + 1, n_epochs, n_iter + 1, n_step, loss))\n",
    "                \n",
    "    X_sent, Y_sent = next(generate_batches(test_set, batch_size=batch_size))\n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    # prepare test data (X_sent and Y_sent) for predicting \n",
    "    # quality and computing value of the loss function\n",
    "    # using function batch_to_ids\n",
    "    X, X_seq_len = batch_to_ids(X_sent, word2id, max_len)\n",
    "    Y, Y_seq_len = batch_to_ids(Y_sent, word2id, max_len)\n",
    "    predictions, loss = model.predict_for_batch_with_loss(session, X, X_seq_len, Y, Y_seq_len)\n",
    "    print('Test: epoch', epoch + 1, 'loss:', loss,)\n",
    "    for x, y, p  in list(zip(X, Y, predictions))[:3]:\n",
    "        print('X:',''.join(ids_to_sentence(x, id2word)))\n",
    "        print('Y:',''.join(ids_to_sentence(y, id2word)))\n",
    "        print('O:',''.join(ids_to_sentence(p, id2word)))\n",
    "        print('')\n",
    "\n",
    "    model_predictions = []\n",
    "    ground_truth = []\n",
    "    invalid_number_prediction_count = 0\n",
    "    # For the whole test set calculate ground-truth values (as integer numbers)\n",
    "    # and prediction values (also as integers) to calculate metrics.\n",
    "    # If generated by model number is not correct (e.g. '1-1'), \n",
    "    # increase invalid_number_prediction_count and don't append this and corresponding\n",
    "    # ground-truth value to the arrays.\n",
    "    for X_batch, Y_batch in generate_batches(test_set, batch_size=batch_size):\n",
    "        ######################################\n",
    "        ######### YOUR CODE HERE #############\n",
    "        ######################################\n",
    "        X, X_seq_len = batch_to_ids(X_batch, word2id, max_len)\n",
    "        Y, Y_seq_len = batch_to_ids(Y_batch, word2id, max_len)\n",
    "        predictions = model.predict_for_batch(session, X, X_seq_len)\n",
    "        for y, p in zip(Y, predictions):\n",
    "            y_sent = ''.join(ids_to_sentence(y, id2word))\n",
    "            y_sent = y_sent[:y_sent.find('$')]\n",
    "            p_sent = ''.join(ids_to_sentence(p, id2word))\n",
    "            index = p_sent.find('$')\n",
    "            if index != -1:\n",
    "                p_sent = p_sent[:index]\n",
    "\n",
    "            if p_sent.isdigit() or (p_sent.startswith('-') and p_sent[1:].isdigit()):\n",
    "                model_predictions.append(int(p_sent))\n",
    "                ground_truth.append(int(y_sent))\n",
    "            else:\n",
    "                invalid_number_prediction_count += 1\n",
    "    \n",
    "    all_model_predictions.append(model_predictions)\n",
    "    all_ground_truth.append(ground_truth)\n",
    "    invalid_number_prediction_counts.append(invalid_number_prediction_count)\n",
    "            \n",
    "print('\\n...training finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjlpMTjVYWGD"
   },
   "source": [
    "Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "CwImGjv1XV_2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "k_-Oyu9UXV6a",
    "outputId": "b3d3c801-da7f-44ad-b983-7460b43ddd63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, MAE: 965.041650, Invalid numbers: 0\n",
      "Epoch: 2, MAE: 387.108900, Invalid numbers: 0\n",
      "Epoch: 3, MAE: 262.053550, Invalid numbers: 0\n",
      "Epoch: 4, MAE: 194.652600, Invalid numbers: 0\n",
      "Epoch: 5, MAE: 186.988050, Invalid numbers: 0\n",
      "Epoch: 6, MAE: 169.329650, Invalid numbers: 0\n",
      "Epoch: 7, MAE: 82.723150, Invalid numbers: 0\n",
      "Epoch: 8, MAE: 52.831950, Invalid numbers: 0\n",
      "Epoch: 9, MAE: 65.271750, Invalid numbers: 0\n",
      "Epoch: 10, MAE: 52.086250, Invalid numbers: 0\n"
     ]
    }
   ],
   "source": [
    "for i, (gts, predictions, invalid_number_prediction_count) in enumerate(zip(all_ground_truth,\n",
    "                                                                            all_model_predictions,\n",
    "                                                                            invalid_number_prediction_counts), 1):\n",
    "    mae = mean_absolute_error(gts, predictions)\n",
    "    print(\"Epoch: %i, MAE: %f, Invalid numbers: %i\" % (i, mae, invalid_number_prediction_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "K22OX28eXV07"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "tiXyMYtTXVzm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "IFaXxipFXVtV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "z2BnY2sOXVr8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "WNIuZ-nZXVlw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "qoHM_aPpXVj1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "vDm7spqfXVea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "YF2LA6TCXVZu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "WucTnWbyXVT3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "quTkJ9OrXVSK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "week4_73_seq2seq models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
